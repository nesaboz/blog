{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python General"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what modules have been imported use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "modulenames = set(sys.modules) & set(globals())\n",
    "allmodules = [sys.modules[name] for name in modulenames]\n",
    "allmodules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if a particular module is imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i, x in enumerate(allmodules) if \"'fastai'\" in str(x)] != []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see memory stats (CPU/GPU/top variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import torch\n",
    "\n",
    "\n",
    "def print_cpu_memory(verbose=True):\n",
    "\n",
    "    # Get the current memory usage\n",
    "    memory_info = psutil.virtual_memory()\n",
    "\n",
    "    # Extract the memory information\n",
    "    total_memory = memory_info.total\n",
    "    available_memory = memory_info.available\n",
    "    used_memory = memory_info.used\n",
    "    percent_memory = memory_info.percent\n",
    "\n",
    "    # Convert bytes to megabytes\n",
    "    total_memory_mb = total_memory / 1024**2\n",
    "    available_memory_mb = available_memory / 1024**2\n",
    "    used_memory_mb = used_memory / 1024**2\n",
    "\n",
    "    if verbose:\n",
    "        # Print the memory information\n",
    "        print(f\"Total CPU memory: {total_memory_mb:.2f} MB\")\n",
    "        print(f\"Available CPU memory: {available_memory_mb:.2f} MB\")\n",
    "        print(f\"Used CPU memory: {used_memory_mb:.2f} MB\")\n",
    "        print(f\"Percentage of used CPU memory: {percent_memory}%\")\n",
    "    else:\n",
    "        print(f\"Percentage of used CPU memory: {percent_memory}%\")\n",
    "\n",
    "\n",
    "def print_gpu_memory():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # Get the default CUDA device\n",
    "        device = torch.cuda.current_device()\n",
    "\n",
    "        # Get the total memory and currently allocated memory on the device\n",
    "        total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "        allocated_memory = torch.cuda.memory_allocated(device)\n",
    "\n",
    "        # Convert bytes to megabytes\n",
    "        total_memory_mb = total_memory / 1024**2\n",
    "        allocated_memory_mb = allocated_memory / 1024**2\n",
    "\n",
    "        # Print the memory information\n",
    "        print(f\"Total GPU memory: {total_memory_mb:.2f} MB\")\n",
    "        print(f\"Allocated GPU memory: {allocated_memory_mb:.2f} MB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available\")\n",
    "\n",
    "\n",
    "def print_top_memory_variables(local_vars, var_number_to_print=5):\n",
    "    \"\"\"Prints top variables in terms of memory. \n",
    "    Usage: `print_top_memory_variables(locals().copy())` can't call locals() in the function itself.\n",
    "\n",
    "    Args:\n",
    "        local_vars (dict): pass `locals().copy()` \n",
    "        var_number_to_print(int): \n",
    "    \"\"\"\n",
    "\n",
    "    # Get the local variables\n",
    "    memory = {}\n",
    "\n",
    "    # Iterate over the local variables and print their sizes\n",
    "    for var_name, var_value in local_vars.items():\n",
    "        var_size = sys.getsizeof(var_value)\n",
    "        memory[var_name] = var_size\n",
    "        \n",
    "    memory_sorted = sorted(memory.items(), key=lambda x: x[1], reverse=True)[:var_number_to_print]\n",
    "    \n",
    "    for (var_name, var_size) in memory_sorted:\n",
    "        print(f\"Variable: {var_name}, Size: {var_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "\n",
    "Profiling code is useful in many ways. Python has a built-in module called `cProfile`. One can also visualize the profile file using `snakeviz`. Here is an example:\n",
    "```python\n",
    "import cProfile\n",
    "import pstats\n",
    "import time\n",
    "\n",
    "def sum(a,b):\n",
    "    return a+b\n",
    "\n",
    "def print_many():\n",
    "    for i in range(100000):\n",
    "        print(i)\n",
    "                \n",
    "def main():\n",
    "    print_many()\n",
    "    print(sum(1,2))\n",
    "    just_wait()\n",
    "    \n",
    "def just_wait():\n",
    "    time.sleep(2)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    with cProfile.Profile() as pr:\n",
    "        main()\n",
    "        \n",
    "    results = pstats.Stats(pr)\n",
    "    results.sort_stats(pstats.SortKey.TIME)\n",
    "    results.print_stats()\n",
    "    results.dump_stats(\"speed_test.prof\")  # run `snakeviz speed_test.prof` to see the results in a browser (pip install snakeviz if needed)\n",
    "```\n",
    "\n",
    "this gives following output:\n",
    "```text\n",
    "   100008 function calls in 2.240 seconds\n",
    "\n",
    "   Ordered by: internal time\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1    2.005    2.005    2.005    2.005 {built-in method time.sleep}\n",
    "   100001    0.220    0.000    0.220    0.000 {built-in method builtins.print}\n",
    "        1    0.015    0.015    0.235    0.235 /Users/nenadbozinovic/Documents/chatbot/speed_test.py:10(print_many)\n",
    "        1    0.000    0.000    0.000    0.000 /Users/nenadbozinovic/miniconda3/envs/blog/lib/python3.11/cProfile.py:118(__exit__)\n",
    "        1    0.000    0.000    2.240    2.240 /Users/nenadbozinovic/Documents/chatbot/speed_test.py:15(main)\n",
    "        1    0.000    0.000    2.005    2.005 /Users/nenadbozinovic/Documents/chatbot/speed_test.py:21(just_wait)\n",
    "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
    "        1    0.000    0.000    0.000    0.000 /Users/nenadbozinovic/Documents/chatbot/speed_test.py:6(sum)\n",
    "```\n",
    "\n",
    "(there is some [extension](https://marketplace.visualstudio.com/items?itemName=p403n1x87.austin-vscode) too that I haven't tried yet).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "website",
   "language": "python",
   "name": "website"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
