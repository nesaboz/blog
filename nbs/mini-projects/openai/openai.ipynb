{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring OpenAI API\n",
    "\n",
    "> From [Educative.io Exploring OpenAI API](https://www.educative.io/courses/exploring-openai-api).\n",
    "\n",
    "- order: 1\n",
    "- image: jet_engine_skier.jpg\n",
    "- toc: true\n",
    "- date: 2024-01-24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go over OpenAI's powerful APIs for generating text and code (GPT-4) and images (DALL-E)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](jet_engine_skier_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "from pypdf import PdfReader\n",
    "from IPython.display import Markdown, display, Image\n",
    "import os\n",
    "from matplotlib import image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def pp(df):\n",
    "    return display( df.style.set_properties(subset=['emails'], **{'text-align': 'left', 'white-space': 'pre-wrap', 'width': '900px'}) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoHObb5Wrafl"
   },
   "source": [
    "## Generate Emails for Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>emails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice socks, great colors, just enough support for wearing with a good pair of sneakers.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love Deborah Harness's Trilogy! Didn't want the story to end and hope they turn this trilogy into a movie. I would love it if she wrote more books to continue this story!!!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SO much quieter than other compressors. VERY quick as well. You will not regret this purchase.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shirt a bit too long, with heavy hem, which inhibits turning over. I cut off the bottom two inches all around, and am now somewhat comfortable. Overall, material is a bit too heavy for my liking.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The quality on these speakers is insanely good and doesn't sound muddy when adjusting bass. Very happy with these.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                               reviews  \\\n",
       "0                                                                                                              Nice socks, great colors, just enough support for wearing with a good pair of sneakers.   \n",
       "1                         Love Deborah Harness's Trilogy! Didn't want the story to end and hope they turn this trilogy into a movie. I would love it if she wrote more books to continue this story!!!   \n",
       "2                                                                                                       SO much quieter than other compressors. VERY quick as well. You will not regret this purchase.   \n",
       "3  Shirt a bit too long, with heavy hem, which inhibits turning over. I cut off the bottom two inches all around, and am now somewhat comfortable. Overall, material is a bit too heavy for my liking.   \n",
       "4                                                                                   The quality on these speakers is insanely good and doesn't sound muddy when adjusting bass. Very happy with these.   \n",
       "\n",
       "  emails  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['reviews', 'emails']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df['reviews'] = [\n",
    "    \"Nice socks, great colors, just enough support for wearing with a good pair of sneakers.\",\n",
    "    \"Love Deborah Harness's Trilogy! Didn't want the story to end and hope they turn this trilogy into a movie. I would love it if she wrote more books to continue this story!!!\",\n",
    "    \"SO much quieter than other compressors. VERY quick as well. You will not regret this purchase.\",\n",
    "    \"Shirt a bit too long, with heavy hem, which inhibits turning over. I cut off the bottom two inches all around, and am now somewhat comfortable. Overall, material is a bit too heavy for my liking.\",\n",
    "    \"The quality on these speakers is insanely good and doesn't sound muddy when adjusting bass. Very happy with these.\",\n",
    "    \"Beautiful watch face. The band looks nice all around. The links do make that squeaky cheapo noise when you swing it back and forth on your wrist which can be embarrassing in front of watch enthusiasts. However, to the naked eye from afar, you can't tell the links are cheap or folded because it is well polished and brushed and the folds are pretty tight for the most part. love the new member of my collection and it looks great. I've had it for about a week and so far it has kept good time despite day 1 which is typical of a new mechanical watch.\"\n",
    "]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take each review and make an email. This email is going to:\n",
    "- Address the concerns expressed in the reviews.\n",
    "- Thank the customers for their purchase.\n",
    "- Encourage them to continue shopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [{\"role\": \"system\", \"content\": \"You are a polite customer support representative.\"}]\n",
    "\n",
    "postfix = \"\\n\\nWrite an email to customers to address the issues put forward in the above review, thank them if they write good comments, and encourage them to make further purchases. Do not give promotion codes or discounts to the customers.\"\n",
    "\n",
    "def make_email(review):\n",
    "\n",
    "    chat_history = chat.copy()\n",
    "    chat_history.append({\"role\":\"user\", \"content\": review + postfix})\n",
    "\n",
    "    reply = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=chat_history\n",
    "        )\n",
    "\n",
    "    return reply.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\n",
    "    \"largest merge of two strings\",\n",
    "    \"sum of unique elements\",\n",
    "    \"longest palindrome\",\n",
    "    \"all possible permutations of a string\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [{\"role\": \"system\", \"content\": \"You are a software engineer for Python.\"}]\n",
    "\n",
    "prefix = \"\\n\\nWrite code that will solve the problem: \"\n",
    "\n",
    "def solve(problem):\n",
    "\n",
    "    chat_history = chat.copy()\n",
    "    chat_history.append({\"role\":\"user\", \"content\": prefix + problem})\n",
    "\n",
    "    reply = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=chat_history\n",
    "        )\n",
    "\n",
    "    return reply.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is how you can write a Python function to calculate the sum of unique elements in a given list.\n",
       "\n",
       "```python\n",
       "def sum_of_unique_elements(lst):\n",
       "    return sum(set(lst))\n",
       "\n",
       "# test the function\n",
       "print(sum_of_unique_elements([1,2,3,3,4,4,5,6,7,8,8,9,10]))\n",
       "```\n",
       "In the function `sum_of_unique_elements(lst)`, `set(lst)` is used to remove duplicates from the list because sets cannot have duplicate elements. Then, `sum(set(lst))` returns the sum of unique elements. \n",
       "\n",
       "For example, if you run the printed test function with a list ` [1,2,3,3,4,4,5,6,7,8,8,9,10]`, it will return `55` because the sum of the unique elements `(1,2,3,4,5,6,7,8,9,10)` is `55`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(solve(problems[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umWrJv6EE6px"
   },
   "source": [
    "## Extract Text From a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4 supports context plus response of up to 8192 tokens (tokens are encoded words into numbers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string, encoding_name):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://arxiv.org/pdf/2312.06272.pdf'\n",
    "# a = requests.get(url)\n",
    "\n",
    "# with open(\"segformer.pdf\", 'wb') as f:\n",
    "#     f.write(a.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"SpaceNet8_final_paper.pdf\")\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text() + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7705"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(text, 'cl100k_base') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's trim it down a little bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5860"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = text[:int(0.8*len(text))]\n",
    "num_tokens_from_string(text2, 'cl100k_base')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should be good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [{\"role\": \"system\", \"content\": \"You are a machine learning researcher that writes blogs about other people research that simplifies machine learning concepts, but does not dumb it down totally.\"}]\n",
    "\n",
    "prefix = \"\\n\\nSummarize the following paper:\"\n",
    "\n",
    "def summarize(text):\n",
    "\n",
    "    chat_history = chat.copy()\n",
    "    chat_history.append({\"role\":\"user\", \"content\": prefix + text})\n",
    "\n",
    "    reply = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=chat_history\n",
    "        )\n",
    "\n",
    "    return reply.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The research paper, \"Comparing Transformers and CNNs on the SpaceNet Flood Detection Challenge,\" is an exploration of different transformer and convolutional neural network (CNN) segmentation architectures in detecting floods caused by hurricanes and heavy rains. The research was done in the context of SpaceNet8 Challenge.\n",
       "\n",
       "The study tested various models including Transformer and U-Net models. It found that large pre-trained Segformer models performed better than the Resnet and U-Net based models. The highest Intersection-over-Union (IoU) was 61% for Segformer, suggesting that attention mechanisms are better suited for detecting building footprints. \n",
       "\n",
       "The research also found flood detection, especially flooded road detection, to be challenging, with the highest IoU of 40%. Further, it was inferred that the pre-training on ImageNet and Cityscapes datasets improved the model's performance moderately compared to pre-training on the ADE20k dataset and significantly over model training from scratch. \n",
       "\n",
       "The researchers leveraged SpaceNet 8 dataset which includes pre-event images and post-event images. The model designated as the Foundation Features network used pre-event images to segment buildings and roads, whereas the Flood network used both pre- and post-event images to predict flood status. \n",
       "\n",
       "The paper also comments on the differences in memory consumption and epoch durations across different models, noting that Segformer models consumed more memory and had longer epochs despite having fewer parameters compared to Resnet34. This is attributed to the attention mechanisms having a quadratic complexity. The study also highlights the impact of data storage and access methods in computational efficiency. \n",
       "\n",
       "In conclusion, the Segformer model, which leverages Transformer, exhibits better performance than CNN-based models (Resnet and U-Net) in the context of the SpaceNet Flood Detection Challenge. However, the paper suggests further improvements might be achieved through normalizing images, applying pre-processing techniques, and leveraging more diverse training data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option2 = summarize(text2)\n",
    "Markdown(option2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.images.generate(\n",
    "    model='dall-e-3',\n",
    "    prompt=\"An scene of a majestic snow covered mountain with cliffs. In the not too far distance, \\\n",
    "        a cool Caucasian male skier adorned in brightly colored winter gear is jumping of the cliff, \\\n",
    "        He has a ripping jet engine securely fastened to his back, its powerful gusts creating an impressive display.\\\n",
    "        He has skip poles in his hands, and is wearing a helmet and goggles. \\\n",
    "        He has skies with rocketed tips, \\\n",
    "        He is captured mid-jump, soaring over a steep, snow-covered cliff. \\\n",
    "        Camera angle should be from the side, about 30 degrees from the skier, and he should be in fact smaller, less then 20 percent of the image. \\\n",
    "        The pristine winter setting is visible beneath him, with majestic snow-capped peaks and a valley blanketed in white. \",\n",
    "    size='1792x1024',\n",
    "    quality='hd',\n",
    "    n=1\n",
    ")\n",
    "display(Markdown(response.data[0].revised_prompt))\n",
    "image_url = response.data[0].url\n",
    "path='usercode/images'\n",
    "os.makedirs(path, exist_ok=True) \n",
    "\n",
    "name = path+'/'+str(datetime.now())\n",
    "\n",
    "img_data = requests.get(image_url).content\n",
    "with open(name+'.jpg', 'wb') as handler:\n",
    "    handler.write(img_data)\n",
    "    \n",
    "plt.figure(figsize=(11,9))\n",
    "img = mpimg.imread(name+'.jpg')\n",
    "\n",
    "imgplot = plt.imshow(img)\n",
    "imgplot.axes.get_xaxis().set_visible(False)\n",
    "imgplot.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def type_like_a_person(text, delay=0.005):\n",
    "    for char in text:\n",
    "        sys.stdout.write(char)\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(delay)\n",
    "    print()  # Move to the next line after the message is complete\n",
    "\n",
    "response = \"\"\"\n",
    "The research paper, \"Comparing Transformers and CNNs on the SpaceNet Flood Detection Challenge,\" is an exploration of different transformer and convolutional neural network (CNN) segmentation architectures in detecting floods caused by hurricanes and heavy rains. The research was done in the context of SpaceNet8 Challenge.\n",
    "\n",
    "The study tested various models including Transformer and U-Net models. It found that large pre-trained Segformer models performed better than the Resnet and U-Net based models. The highest Intersection-over-Union (IoU) was 61% for Segformer, suggesting that attention mechanisms are better suited for detecting building footprints.\n",
    "\n",
    "The research also found flood detection, especially flooded road detection, to be challenging, with the highest IoU of 40%. Further, it was inferred that the pre-training on ImageNet and Cityscapes datasets improved the model's performance moderately compared to pre-training on the ADE20k dataset and significantly over model training from scratch.\n",
    "\n",
    "The researchers leveraged SpaceNet 8 dataset which includes pre-event images and post-event images. The model designated as the Foundation Features network used pre-event images to segment buildings and roads, whereas the Flood network used both pre- and post-event images to predict flood status.\n",
    "\n",
    "The paper also comments on the differences in memory consumption and epoch durations across different models, noting that Segformer models consumed more memory and had longer epochs despite having fewer parameters compared to Resnet34. This is attributed to the attention mechanisms having a quadratic complexity. The study also highlights the impact of data storage and access methods in computational efficiency.\n",
    "\n",
    "In conclusion, the Segformer model, which leverages Transformer, exhibits better performance than CNN-based models (Resnet and U-Net) in the context of the SpaceNet Flood Detection Challenge. However, the paper suggests further improvements might be achieved through normalizing images, applying pre-processing techniques, and leveraging more diverse training data.\"  # Replace with the actual API response\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "type_like_a_person(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
