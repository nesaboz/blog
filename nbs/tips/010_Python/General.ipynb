{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python General"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what modules have been imported use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "modulenames = set(sys.modules) & set(globals())\n",
    "allmodules = [sys.modules[name] for name in modulenames]\n",
    "allmodules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if a particular module is imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i, x in enumerate(allmodules) if \"'fastai'\" in str(x)] != []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see memory stats (CPU/GPU/top variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import torch\n",
    "\n",
    "\n",
    "def print_cpu_memory(verbose=True):\n",
    "\n",
    "    # Get the current memory usage\n",
    "    memory_info = psutil.virtual_memory()\n",
    "\n",
    "    # Extract the memory information\n",
    "    total_memory = memory_info.total\n",
    "    available_memory = memory_info.available\n",
    "    used_memory = memory_info.used\n",
    "    percent_memory = memory_info.percent\n",
    "\n",
    "    # Convert bytes to megabytes\n",
    "    total_memory_mb = total_memory / 1024**2\n",
    "    available_memory_mb = available_memory / 1024**2\n",
    "    used_memory_mb = used_memory / 1024**2\n",
    "\n",
    "    if verbose:\n",
    "        # Print the memory information\n",
    "        print(f\"Total CPU memory: {total_memory_mb:.2f} MB\")\n",
    "        print(f\"Available CPU memory: {available_memory_mb:.2f} MB\")\n",
    "        print(f\"Used CPU memory: {used_memory_mb:.2f} MB\")\n",
    "        print(f\"Percentage of used CPU memory: {percent_memory}%\")\n",
    "    else:\n",
    "        print(f\"Percentage of used CPU memory: {percent_memory}%\")\n",
    "\n",
    "\n",
    "def print_gpu_memory():\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # Get the default CUDA device\n",
    "        device = torch.cuda.current_device()\n",
    "\n",
    "        # Get the total memory and currently allocated memory on the device\n",
    "        total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "        allocated_memory = torch.cuda.memory_allocated(device)\n",
    "\n",
    "        # Convert bytes to megabytes\n",
    "        total_memory_mb = total_memory / 1024**2\n",
    "        allocated_memory_mb = allocated_memory / 1024**2\n",
    "\n",
    "        # Print the memory information\n",
    "        print(f\"Total GPU memory: {total_memory_mb:.2f} MB\")\n",
    "        print(f\"Allocated GPU memory: {allocated_memory_mb:.2f} MB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available\")\n",
    "\n",
    "\n",
    "def print_top_memory_variables(local_vars, var_number_to_print=5):\n",
    "    \"\"\"Prints top variables in terms of memory. \n",
    "    Usage: `print_top_memory_variables(locals().copy())` can't call locals() in the function itself.\n",
    "\n",
    "    Args:\n",
    "        local_vars (dict): pass `locals().copy()` \n",
    "        var_number_to_print(int): \n",
    "    \"\"\"\n",
    "\n",
    "    # Get the local variables\n",
    "    memory = {}\n",
    "\n",
    "    # Iterate over the local variables and print their sizes\n",
    "    for var_name, var_value in local_vars.items():\n",
    "        var_size = sys.getsizeof(var_value)\n",
    "        memory[var_name] = var_size\n",
    "        \n",
    "    memory_sorted = sorted(memory.items(), key=lambda x: x[1], reverse=True)[:var_number_to_print]\n",
    "    \n",
    "    for (var_name, var_size) in memory_sorted:\n",
    "        print(f\"Variable: {var_name}, Size: {var_size} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "website",
   "language": "python",
   "name": "website"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
